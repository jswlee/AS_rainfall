{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# American Samoa Rainfall Prediction Testing Notebook\n",
    "\n",
    "This notebook allows you to test and run the entire rainfall prediction pipeline from data processing to ensemble model training. It provides an interactive way to adjust parameters and run each step of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's set up the environment and import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/jlee/Desktop/github/AS_rainfall\n",
      "TensorFlow version: 2.18.0\n",
      "GPU available: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "import yaml\n",
    "\n",
    "# Define project root directory\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd()))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Add all script directories to path\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, '1_Process_Rainfall_Data', 'scripts'))\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'scripts'))\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, '3_Hyperparameter_Tuning', 'scripts'))\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, '4_Train_Best_Model', 'scripts'))\n",
    "sys.path.append(os.path.join(PROJECT_ROOT, '5_Train_Ensemble', 'scripts'))\n",
    "\n",
    "# Set up TensorFlow\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These functions will help us run terminal commands and import modules from the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run terminal commands\n",
    "def run_command(command):\n",
    "    \"\"\"Run a terminal command and return the output\"\"\"\n",
    "    import subprocess\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"Error executing command: {command}\")\n",
    "        print(f\"Error message: {result.stderr}\")\n",
    "    return result.stdout\n",
    "\n",
    "# Function to import a module dynamically\n",
    "def import_module_from_file(module_path):\n",
    "    \"\"\"Import a module from a file path\"\"\"\n",
    "    import importlib.util\n",
    "    module_name = os.path.basename(module_path).replace('.py', '')\n",
    "    spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Process Rainfall Data\n",
    "\n",
    "This section processes raw rainfall data into monthly aggregates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rainfall data from /Users/jlee/Desktop/github/AS_rainfall/raw_data/rainfall to /Users/jlee/Desktop/github/AS_rainfall/1_Process_Rainfall_Data/output/monthly_rainfall\n",
      "Processing rainfall data from /Users/jlee/Desktop/github/AS_rainfall/raw_data/rainfall\n",
      "Output will be saved to /Users/jlee/Desktop/github/AS_rainfall/1_Process_Rainfall_Data/output/monthly_rainfall\n",
      "Processing rainfall data from /Users/jlee/Desktop/github/AS_rainfall/raw_data/rainfall to /Users/jlee/Desktop/github/AS_rainfall/1_Process_Rainfall_Data/output/monthly_rainfall\n",
      "Processed: satala.csv -> satala_monthly.csv [1/21]\n",
      "Processed: airport5101.csv -> airport5101_monthly.csv [2/21]\n",
      "Processed: pioa_afono.csv -> pioa_afono_monthly.csv [3/21]\n",
      "Processed: aua.csv -> aua_monthly.csv [4/21]\n",
      "Processed: siufaga_WRCC.csv -> siufaga_WRCC_monthly.csv [5/21]\n",
      "Processed: airport80.csv -> airport80_monthly.csv [6/21]\n",
      "Processed: vaipito_res.csv -> vaipito_res_monthly.csv [7/21]\n",
      "Processed: aasufou80.csv -> aasufou80_monthly.csv [8/21]\n",
      "Processed: maloata.csv -> maloata_monthly.csv [9/21]\n",
      "Processed: toa_ridge_WRCC.csv -> toa_ridge_WRCC_monthly.csv [10/21]\n",
      "Processed: aasufou90.csv -> aasufou90_monthly.csv [11/21]\n",
      "Processed: vaipito2000.csv -> vaipito2000_monthly.csv [12/21]\n",
      "Processed: malaeimi.csv -> malaeimi_monthly.csv [13/21]\n",
      "Processed: masefau.csv -> masefau_monthly.csv [14/21]\n",
      "Processed: fagaitua.csv -> fagaitua_monthly.csv [15/21]\n",
      "Processed: malaeimi_1691.csv -> malaeimi_1691_monthly.csv [16/21]\n",
      "Processed: iliili.csv -> iliili_monthly.csv [17/21]\n",
      "Processed: aoloafou.csv -> aoloafou_monthly.csv [18/21]\n",
      "Processed: mt_alava.csv -> mt_alava_monthly.csv [19/21]\n",
      "Processed: matatula.csv -> matatula_monthly.csv [20/21]\n",
      "Processed: aunuu.csv -> aunuu_monthly.csv [21/21]\n",
      "Completed processing 21 out of 21 files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the rainfall processing module\n",
    "rainfall_daily_to_monthly_path = os.path.join(PROJECT_ROOT, '1_Process_Rainfall_Data', 'scripts', 'rainfall_daily_to_monthly.py')\n",
    "rainfall_module = import_module_from_file(rainfall_daily_to_monthly_path)\n",
    "\n",
    "# Define parameters\n",
    "input_dir = os.path.join(PROJECT_ROOT, 'raw_data', 'rainfall')\n",
    "output_dir = os.path.join(PROJECT_ROOT, '1_Process_Rainfall_Data', 'output', 'monthly_rainfall')\n",
    "\n",
    "# Create a class to mimic argparse\n",
    "class Args:\n",
    "    def __init__(self, input_dir, output_dir):\n",
    "        self.input = input_dir\n",
    "        self.output = output_dir\n",
    "\n",
    "args = Args(input_dir, output_dir)\n",
    "\n",
    "# Run the rainfall processing\n",
    "print(f\"Processing rainfall data from {input_dir} to {output_dir}\")\n",
    "try:\n",
    "    cmd = f\"python3 {rainfall_daily_to_monthly_path} --input_dir {input_dir} --output_dir {output_dir}\"\n",
    "    output = run_command(cmd)\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f\"Error processing rainfall data: {e}\")\n",
    "    # Alternatively, run as a terminal command\n",
    "    cmd = f\"python3 {rainfall_daily_to_monthly_path} --input {input_dir} --output {output_dir}\"\n",
    "    output = run_command(cmd)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create ML Data\n",
    "\n",
    "This section creates machine learning datasets by combining rainfall data with climate variables and DEM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config_utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Configuration:\n",
      "  dem_path: /Users/jlee/Desktop/github/AS_rainfall/raw_data/DEM/DEM_Tut1.tif\n",
      "  climate_data_path: /Users/jlee/Desktop/github/AS_rainfall/2_Create_ML_Data/output/processed_climate_data.nc\n",
      "  raw_climate_dir: /Users/jlee/Desktop/github/AS_rainfall/raw_data/climate_variables\n",
      "  rainfall_dir: /Users/jlee/Desktop/github/AS_rainfall/1_Process_Rainfall_Data/output/monthly_rainfall\n",
      "  station_locations_path: /Users/jlee/Desktop/github/AS_rainfall/raw_data/AS_raingages/as_raingage_list2.csv\n",
      "  output_dir: /Users/jlee/Desktop/github/AS_rainfall/2_Create_ML_Data/output/custom_run\n",
      "  grid_size: 7\n",
      "  patch_sizes: local=5, regional=3\n",
      "  km_per_cell: local=1.5, regional=8\n"
     ]
    }
   ],
   "source": [
    "# Create a custom configuration file\n",
    "custom_config_path = os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'config', 'custom_config.yaml')\n",
    "\n",
    "# Define custom configuration\n",
    "custom_config = {\n",
    "    'paths': {\n",
    "        'dem': \"raw_data/DEM/DEM_Tut1.tif\",\n",
    "        'climate_data': \"2_Create_ML_Data/output/processed_climate_data.nc\",\n",
    "        'raw_climate': \"raw_data/climate_variables\",\n",
    "        'rainfall': \"1_Process_Rainfall_Data/output/monthly_rainfall\",\n",
    "        'stations': \"raw_data/AS_raingages/as_raingage_list2.csv\",\n",
    "        'output': \"2_Create_ML_Data/output/custom_run\"\n",
    "    },\n",
    "    'model': {\n",
    "        'grid_size': 7,  # Changed from 5 to 7\n",
    "        'patch_sizes': {\n",
    "            'local': 5,    # Changed from 3 to 5\n",
    "            'regional': 3\n",
    "        },\n",
    "        'km_per_cell': {\n",
    "            'local': 1.5,  # Changed from 2 to 1.5\n",
    "            'regional': 8\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the custom configuration to a YAML file\n",
    "os.makedirs(os.path.dirname(custom_config_path), exist_ok=True)\n",
    "with open(custom_config_path, 'w') as f:\n",
    "    yaml.dump(custom_config, f, default_flow_style=False)\n",
    "\n",
    "# Load the custom configuration\n",
    "custom_config_loaded = load_config(custom_config_path)\n",
    "\n",
    "# Display the custom configuration\n",
    "print(\"Custom Configuration:\")\n",
    "for key, value in custom_config_loaded.items():\n",
    "    if key not in ['patch_sizes', 'km_per_cell']:\n",
    "        print(f\"  {key}: {value}\")\n",
    "print(f\"  patch_sizes: local={custom_config_loaded['patch_sizes']['local']}, regional={custom_config_loaded['patch_sizes']['regional']}\")\n",
    "print(f\"  km_per_cell: local={custom_config_loaded['km_per_cell']['local']}, regional={custom_config_loaded['km_per_cell']['regional']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ML datasets...\n",
      "Found 11 raw climate data files in /Users/jlee/Desktop/github/AS_rainfall/raw_data/climate_variables\n",
      "Found existing processed climate data at: /Users/jlee/Desktop/github/AS_rainfall/2_Create_ML_Data/output/processed_climate_data.nc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the ML data creation module\n",
    "pipeline_path = os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'scripts', 'rainfall_prediction_pipeline.py')\n",
    "\n",
    "# Run the pipeline as a terminal command\n",
    "print(\"Creating ML datasets...\")\n",
    "cmd = f\"python3 {pipeline_path}\"\n",
    "output = run_command(cmd)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning\n",
    "\n",
    "This section performs hyperparameter tuning for the LAND-inspired model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hyperparameter tuning module\n",
    "tuning_path = os.path.join(PROJECT_ROOT, '3_Hyperparameter_Tuning', 'scripts', 'extended_hyperparameter_tuning.py')\n",
    "tuning_module = import_module_from_file(tuning_path)\n",
    "\n",
    "# Define parameters\n",
    "features_path = os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'output', 'csv_data', 'features.csv')\n",
    "targets_path = os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'output', 'csv_data', 'targets.csv')\n",
    "test_indices_path = os.path.join(PROJECT_ROOT, '3_Hyperparameter_Tuning', 'output', 'test_indices.pkl')\n",
    "output_dir = os.path.join(PROJECT_ROOT, '3_Hyperparameter_Tuning', 'output', 'land_model_extended_tuner')\n",
    "max_trials = 10  # Reduced for testing\n",
    "epochs = 20      # Reduced for testing\n",
    "resume = True    # Resume from previous tuning if available\n",
    "\n",
    "# Create a namespace to mimic argparse\n",
    "class TuningArgs:\n",
    "    def __init__(self, features_path, targets_path, test_indices_path, output_dir, max_trials, epochs, resume):\n",
    "        self.features_path = features_path\n",
    "        self.targets_path = targets_path\n",
    "        self.test_indices_path = test_indices_path\n",
    "        self.output_dir = output_dir\n",
    "        self.max_trials = max_trials\n",
    "        self.executions_per_trial = 1\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = 314\n",
    "        self.n_folds = 5\n",
    "        self.cv_seed = 42\n",
    "        self.resume = resume\n",
    "\n",
    "tuning_args = TuningArgs(\n",
    "    features_path=features_path,\n",
    "    targets_path=targets_path,\n",
    "    test_indices_path=test_indices_path,\n",
    "    output_dir=output_dir,\n",
    "    max_trials=max_trials,\n",
    "    epochs=epochs,\n",
    "    resume=resume\n",
    ")\n",
    "\n",
    "# Run hyperparameter tuning\n",
    "print(f\"Running hyperparameter tuning with {max_trials} trials and {epochs} epochs per trial\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Option 1: Run the main function directly with our args\n",
    "# Uncomment this to run directly (may take a long time)\n",
    "# tuning_module.main(tuning_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Run as a terminal command with specific parameters\n",
    "# This is more flexible and can be interrupted\n",
    "cmd = f\"python3 {tuning_path} \\\n",
    "    --features_path {features_path} \\\n",
    "    --targets_path {targets_path} \\\n",
    "    --test_indices_path {test_indices_path} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --max_trials {max_trials} \\\n",
    "    --epochs {epochs} \\\n",
    "    {'--resume' if resume else ''}\"\n",
    "\n",
    "print(f\"Command: {cmd}\")\n",
    "# Uncomment to run (may take a long time)\n",
    "# output = run_command(cmd)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Best Model\n",
    "\n",
    "This section trains the best model using the optimal hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the best model training module\n",
    "best_model_path = os.path.join(PROJECT_ROOT, '4_Train_Best_Model', 'scripts', 'train_best_model.py')\n",
    "best_model_module = import_module_from_file(best_model_path)\n",
    "\n",
    "# Define parameters\n",
    "data_path = os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'output', 'rainfall_prediction_data.h5')\n",
    "hyperparams_path = os.path.join(PROJECT_ROOT, '3_Hyperparameter_Tuning', 'output', 'land_model_extended_tuner', 'current_best_hyperparameters.py')\n",
    "output_dir = os.path.join(PROJECT_ROOT, '4_Train_Best_Model', 'output')\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "test_split = 0.1\n",
    "val_split = 0.1\n",
    "random_seed = 42\n",
    "\n",
    "# Create a namespace to mimic argparse\n",
    "class BestModelArgs:\n",
    "    def __init__(self, data_path, hyperparams_path, output_dir, epochs, batch_size, test_split, val_split, random_seed):\n",
    "        self.data_path = data_path\n",
    "        self.hyperparams_path = hyperparams_path\n",
    "        self.output_dir = output_dir\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.test_split = test_split\n",
    "        self.val_split = val_split\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "best_model_args = BestModelArgs(\n",
    "    data_path=data_path,\n",
    "    hyperparams_path=hyperparams_path,\n",
    "    output_dir=output_dir,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    test_split=test_split,\n",
    "    val_split=val_split,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "\n",
    "# Run best model training\n",
    "print(f\"Training best model with {epochs} epochs and batch size {batch_size}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Option 1: Run the main function directly with our args\n",
    "# Uncomment this to run directly\n",
    "# best_model_module.main(best_model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Run as a terminal command with specific parameters\n",
    "cmd = f\"python3 {best_model_path} \\\n",
    "    --data_path {data_path} \\\n",
    "    --hyperparams_path {hyperparams_path} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --epochs {epochs} \\\n",
    "    --batch_size {batch_size} \\\n",
    "    --test_split {test_split} \\\n",
    "    --val_split {val_split} \\\n",
    "    --random_seed {random_seed}\"\n",
    "\n",
    "print(f\"Command: {cmd}\")\n",
    "# Uncomment to run\n",
    "# output = run_command(cmd)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Ensemble Model\n",
    "\n",
    "This section trains an ensemble of models for improved prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ensemble training module\n",
    "ensemble_path = os.path.join(PROJECT_ROOT, '5_Train_Ensemble', 'scripts', 'simple_ensemble.py')\n",
    "ensemble_module = import_module_from_file(ensemble_path)\n",
    "\n",
    "# Define parameters\n",
    "data_path = os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'output', 'rainfall_prediction_data.h5')\n",
    "hyperparams_path = os.path.join(PROJECT_ROOT, '3_Hyperparameter_Tuning', 'output', 'land_model_extended_tuner', 'current_best_hyperparameters.py')\n",
    "output_dir = os.path.join(PROJECT_ROOT, '5_Train_Ensemble', 'output')\n",
    "n_folds = 5\n",
    "n_models_per_fold = 3\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "random_seed = 42\n",
    "\n",
    "# Create a namespace to mimic argparse\n",
    "class EnsembleArgs:\n",
    "    def __init__(self, data_path, hyperparams_path, output_dir, n_folds, n_models_per_fold, epochs, batch_size, random_seed):\n",
    "        self.data_path = data_path\n",
    "        self.hyperparams_path = hyperparams_path\n",
    "        self.output_dir = output_dir\n",
    "        self.n_folds = n_folds\n",
    "        self.n_models_per_fold = n_models_per_fold\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "ensemble_args = EnsembleArgs(\n",
    "    data_path=data_path,\n",
    "    hyperparams_path=hyperparams_path,\n",
    "    output_dir=output_dir,\n",
    "    n_folds=n_folds,\n",
    "    n_models_per_fold=n_models_per_fold,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    random_seed=random_seed\n",
    ")\n",
    "\n",
    "# Run ensemble training\n",
    "print(f\"Training ensemble with {n_folds} folds, {n_models_per_fold} models per fold, {epochs} epochs\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Option 1: Run the main function directly with our args\n",
    "# Uncomment this to run directly\n",
    "# ensemble_module.main(ensemble_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Run as a terminal command with specific parameters\n",
    "cmd = f\"python3 {ensemble_path} \\\n",
    "    --data_path {data_path} \\\n",
    "    --hyperparams_path {hyperparams_path} \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --n_folds {n_folds} \\\n",
    "    --n_models_per_fold {n_models_per_fold} \\\n",
    "    --epochs {epochs} \\\n",
    "    --batch_size {batch_size} \\\n",
    "    --random_seed {random_seed}\"\n",
    "\n",
    "print(f\"Command: {cmd}\")\n",
    "# Uncomment to run\n",
    "# output = run_command(cmd)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results\n",
    "\n",
    "This section visualizes the results from the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display ensemble results\n",
    "ensemble_summary_path = os.path.join(PROJECT_ROOT, '5_Train_Ensemble', 'output', 'simple_ensemble', 'ensemble_summary.txt')\n",
    "\n",
    "if os.path.exists(ensemble_summary_path):\n",
    "    with open(ensemble_summary_path, 'r') as f:\n",
    "        ensemble_summary = f.read()\n",
    "    print(\"Ensemble Summary:\")\n",
    "    print(ensemble_summary)\n",
    "else:\n",
    "    print(f\"Ensemble summary not found at {ensemble_summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display ensemble scatter plot\n",
    "ensemble_scatter_path = os.path.join(PROJECT_ROOT, '5_Train_Ensemble', 'output', 'simple_ensemble', 'ensemble_scatter.png')\n",
    "\n",
    "if os.path.exists(ensemble_scatter_path):\n",
    "    from IPython.display import Image\n",
    "    display(Image(filename=ensemble_scatter_path))\n",
    "else:\n",
    "    print(f\"Ensemble scatter plot not found at {ensemble_scatter_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Testing\n",
    "\n",
    "This section allows you to perform custom tests on the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load and test a specific model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Path to a trained model\n",
    "model_path = os.path.join(PROJECT_ROOT, '5_Train_Ensemble', 'output', 'simple_ensemble', 'fold_1', 'model_1', 'model.h5')\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    # Load the model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(f\"Loaded model from {model_path}\")\n",
    "    print(f\"Model summary:\")\n",
    "    model.summary()\n",
    "else:\n",
    "    print(f\"Model not found at {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make predictions with a sample input\n",
    "# This requires loading test data and preprocessing it correctly\n",
    "# You would need to adapt this to your specific data format\n",
    "\n",
    "# Load data_utils to help with data loading\n",
    "data_utils_path = os.path.join(PROJECT_ROOT, '4_Train_Best_Model', 'scripts', 'data_utils.py')\n",
    "data_utils = import_module_from_file(data_utils_path)\n",
    "\n",
    "# Example of loading data and making predictions\n",
    "# Uncomment and adapt as needed\n",
    "\n",
    "# data_path = os.path.join(PROJECT_ROOT, '2_Create_ML_Data', 'output', 'rainfall_prediction_data.h5')\n",
    "# data = data_utils.load_data(data_path)\n",
    "# test_features = data['features']['test']\n",
    "# test_targets = data['targets']['test']\n",
    "# \n",
    "# # Make predictions\n",
    "# predictions = model.predict(test_features)\n",
    "# \n",
    "# # Convert back to inches (if needed)\n",
    "# predictions_inches = predictions * 100\n",
    "# test_targets_inches = test_targets * 100\n",
    "# \n",
    "# # Plot predictions vs. actual\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.scatter(test_targets_inches, predictions_inches, alpha=0.5)\n",
    "# plt.plot([0, max(test_targets_inches)], [0, max(test_targets_inches)], 'r--')\n",
    "# plt.xlabel('Actual Rainfall (inches)')\n",
    "# plt.ylabel('Predicted Rainfall (inches)')\n",
    "# plt.title('Predicted vs. Actual Rainfall')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
